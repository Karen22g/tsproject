{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dfd47ad-0fd6-4f32-8dff-22f24a6298a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from joblib import dump, load\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import re\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "import statsmodels.api as sm\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a878eee-ab06-408d-b844-655624347705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(serie, trainportion):\n",
    "    perct = math.ceil(len(ts) * trainportion)\n",
    "    perc2 = math.ceil(len(ts)*((1 - trainportion)/2))\n",
    "    train = serie[0:perct]\n",
    "    validation = serie[perct:perct+perc2]\n",
    "    test = serie[perct+perc2:]\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ef7e906-1914-4bdf-b3a3-f5afd7d81aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"loadsts.xlsx\")\n",
    "df.index = df['Posted_date']\n",
    "df.index.freq = 'D'\n",
    "df['loads_escaler'] = df['Loads']\n",
    "ts = df['Loads']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ts_esc = scaler.fit_transform(np.array(df['loads_escaler']).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75aa0aa5-dcb1-4259-a386-aaf59c723104",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split(ts, 0.7)\n",
    "train_esc, val_esc, test_esc = split(ts_esc, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51dec72a-5ab7-41c9-bb7e-e9d99a4af9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeXy(ts, nb_timesteps):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(nb_timesteps, ts.shape[0]):\n",
    "        X.append(list(ts[i-nb_timesteps:i-1])) #Regressors\n",
    "        y.append(ts[i]) #Target\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96673c5c-986f-45f4-a9e6-11769af6c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makeXy(ts, 5) #probar para 3, 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ed1e653-0fa2-41c8-804c-e5e639086ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = makeXy(train_esc, 7)\n",
    "X_val, y_val = makeXy(val_esc,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42cb67c6-5af4-4aa7-8ce8-4705f70cb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculo de los errores\n",
    "def errors(y_pred, y_real):\n",
    "    \n",
    "    mae = mean_absolute_error(y_real, y_pred)\n",
    "    mape = 100*(sum(abs(((y_real - y_pred)/y_real)))/len(y_real))\n",
    "    mse = mean_squared_error(y_real , y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_real, y_pred)\n",
    "    \n",
    "    return mae, mape, mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27368315-d757-4a7b-aaae-68a09c296e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecast\n",
    "def forecast_nw(best_model, X_val):\n",
    "    preds = best_model.predict(X_val)\n",
    "    preds = scaler.inverse_transform(preds)\n",
    "    preds = np.squeeze(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee7a5cd9-7727-43bf-88d9-834b864a43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear el modelo\n",
    "def create_mlp(neurons, dropout_rate):\n",
    "    \n",
    "    input_layer = Input(shape=(7,), dtype='float32')\n",
    "    dense_layer = Dense(neurons, activation='tanh')(input_layer)\n",
    "    dropout_layer = Dropout(dropout_rate)(dense_layer)\n",
    "    output_layer = Dense(1, activation='linear')(dropout_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7f690-353c-4501-80cd-52d1b2180e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionar el mejor modelo\n",
    "def select_mlp(model, batch_size,X_train, y_train, X_val, y_val):\n",
    "\n",
    "    save_weights_at = os.path.join('keras_models', f'{model.name}_weights_batch{batch_size}_{{epoch:02d}}-{{val_loss:.4f}}.keras')\n",
    "    save_best = ModelCheckpoint(save_weights_at, monitor='val_loss', verbose=0,\n",
    "                            save_best_only=True, save_weights_only=False, mode='min', save_freq='epoch');\n",
    "    \n",
    "    history_filename = f'history_{model.name}_batch{batch_size}.joblib'\n",
    "    history_airp = None\n",
    "\n",
    "    if os.path.exists(history_filename):\n",
    "        history_airp = load(history_filename)\n",
    "        print(\"El archivo '{history_filename}' ya existe. Se ha cargado el historial del entrenamiento.\")\n",
    "        \n",
    "    else:\n",
    "        history_airp = model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=10,\n",
    "                 verbose=2, callbacks=[save_best], validation_data=(X_val, y_val),\n",
    "                 shuffle=True);\n",
    "        dump(history_airp.history, history_filename)\n",
    "        print(\"El entrenamiento se ha completado y el historial ha sido guardado en '{history_filename}'\")\n",
    "\n",
    "    model_dir = 'keras_models'\n",
    "    files = os.listdir(model_dir)\n",
    "    pattern = rf\"{re.escape(model.name)}_weights_batch{batch_size}_(\\d+)-([\\d\\.]+)\\.keras\"\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_file = None\n",
    "    best_model = None\n",
    "    \n",
    "    for file in files:\n",
    "        match = re.match(pattern, file)\n",
    "        if match:\n",
    "            epoch = int(match.group(1))\n",
    "            val_loss = float(match.group(2))\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_file = file\n",
    "\n",
    "    if best_model_file:\n",
    "        best_model_path = os.path.join(model_dir, best_model_file)\n",
    "        print(f\"Cargando el mejor modelo: {best_model_file} con val_loss: {best_val_loss}\")\n",
    "        best_model = load_model(best_model_path)\n",
    "    else:\n",
    "        print(\"No se encontraron archivos de modelos que coincidan con el patrón.\")\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d382a78-dde5-4a24-b80f-e91bdb298edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando: Neuronas: 10, Dropout: 0.2, Batchsize: 16\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'select_mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m create_mlp(neurons, dropout_rate)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#seleccionar el mejor modelo\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mselect_mlp\u001b[49m(model, batch_size,X_train, y_train, X_val, y_val)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#pronosticar validación\u001b[39;00m\n\u001b[0;32m     21\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m forecast_nw(best_model, X_val)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'select_mlp' is not defined"
     ]
    }
   ],
   "source": [
    "#probar los distintos modelos\n",
    "dropout_rates = [0.2, 0.4]#, 0.6, 0.8]\n",
    "neurons_list = [10, 100]#, 1000, 10000]\n",
    "batch_sizes = [16, 32]#, 64, 128]\n",
    "\n",
    "val_result = []\n",
    "test_result = []\n",
    "\n",
    "#probar todas las combinaciones\n",
    "for dropout_rate in dropout_rates:\n",
    "    for neurons in neurons_list:\n",
    "        for batch_size in batch_sizes:\n",
    "            \n",
    "            print(f\"Evaluando: Neuronas: {neurons}, Dropout: {dropout_rate}, Batchsize: {batch_size}\")\n",
    "            model = create_mlp(neurons, dropout_rate)\n",
    "\n",
    "            #seleccionar el mejor modelo\n",
    "            best_model = select_mlp(model, batch_size,X_train, y_train, X_val, y_val)\n",
    "\n",
    "            #pronosticar validación\n",
    "            val_pred = forecast_nw(best_model, X_val)\n",
    "            mae_v, mape_v, mse_v, rmse_v, r2_v = errors(val_pred, df_val['Price'].reset_index(drop=True).loc[7:])\n",
    "\n",
    "            #calculo de residuos residuals = df_val['Price'].reset_index(drop=True).loc[7:]-pred_PRES\n",
    "            #con mejor modelo se revisan supuestos del error en entrenamiento\n",
    "            #con mejor modelo se revisan supuestos del error en test\n",
    "            \n",
    "            #con mejor modelo de esa combinación se predice test\n",
    "            \n",
    "            #pronosticar test\n",
    "            #test_pred = forecast_nw(best_model, X_test)\n",
    "            #mae_v, mape_v, mse_v, rmse_v, r2_v = errors(test_pred, df_test['Price'].reset_index(drop=True).loc[7:])\n",
    "\n",
    "            #Se guardan los resultados\n",
    "            val_result.append(['price', \"mlp\", dropout_rate, neurons, batch_size, mape_v, mae_v, mse_v, rmse_v, r2_v]) #jb_pvalue_m, ljung_box_pvalue_m])\n",
    "            #test_result.append(['price', \"mlp\", dropout_rate, neurons, batch_size, mape_t, mae_t, mse_t, rmse_t, r2_t, ljung_box_pvalue_t])\n",
    "             \n",
    "#dfval = pd.DataFrame(val_result, columns=['variable','model', 'val_size', 'MAPE', 'MAE', 'MSE', 'RMSE', 'R2', 'jarque-bera_p','ljungbox_p'])\n",
    "#dftest = pd.DataFrame(test_result, columns=['variable','model', 'test_size', 'MAPE', 'MAE', 'MSE', 'RMSE', 'R2', 'ljungbox_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eafee0-a42a-4f20-aa12-f5ef04f9a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 5.5))\n",
    "plt.plot(range(50), df_val['Price'].reset_index(drop=True).loc[7:56], linestyle='-', marker='*', color='r')\n",
    "plt.plot(range(50), pred_PRES[:50], linestyle='-', marker='.', color='b')\n",
    "plt.legend(['Actual','Predicted'], loc=2)\n",
    "plt.title('Actual vs Predicted price')\n",
    "plt.ylabel('Air Pressure')\n",
    "plt.xlabel('Index');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae7204-c5f2-470e-a494-1e2623f22a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear el modelo\n",
    "def create_lstm(neurons, dropout_rate):\n",
    "    \n",
    "    input_layer = Input(shape=(7,1), dtype='float32')\n",
    "    lstm_layer1 = LSTM(neurons, input_shape=(7,1), return_sequences=True)(input_layer)\n",
    "    dropout_layer = Dropout(drop_out)(lstm_layer2)\n",
    "    output_layer = Dense(1, activation='linear')(dropout_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f76eb7-7b06-4065-a438-79c92358249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RNN(neurons, input_shape, activation,dropout_rate): #Creación RNN\n",
    "    model_RNN = Sequential()\n",
    "    # Capa SimpleRNN con 10 neuronas\n",
    "    model_RNN.add(SimpleRNN(neurons, input_shape=input_shape, \n",
    "                        activation=activation, return_sequences=False))\n",
    "    model_RNN.add(Dropout(dropout_rate))\n",
    "    model_RNN.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model_RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
